{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46731cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f797378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://api.theirstack.com/v1/jobs/search\"\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {os.getenv('their_stack_api_key')}\"}\n",
    "\n",
    "if os.path.exists(\"/home/giuseppe/projetos-pessoais/linkedin-bot/data/raw/jobs_1.csv\"):\n",
    "    df_jobs = pd.read_csv(\"/home/giuseppe/projetos-pessoais/linkedin-bot/data/raw/jobs_1.csv\")\n",
    "else:\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    request = response.json()\n",
    "    df_jobs = pd.DataFrame(request[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec1f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
    "    openai_api_key=os.getenv('TOGETHER_API_KEY'),\n",
    "    openai_api_base=\"https://api.together.xyz/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizeDescription(BaseModel):\n",
    "    resume: str = Field(\n",
    "        description=\"Summarize the relevant informations contained in descrption  job position\"\n",
    "    )\n",
    "\n",
    "    smart_working: bool = Field(\n",
    "        description=\"Flag with true or false if this jobs in remote or not\"\n",
    "    )\n",
    "\n",
    "    required: str = Field(\n",
    "        description=\"The required skills and qualifications for the job position\"\n",
    "    )\n",
    "    nice_to_have: str = Field(\n",
    "        description=\"The nice to have skills and qualifications for the job position\"\n",
    "    )\n",
    "    company: str = Field(description=\"Summarize the company name and its mission\")\n",
    "    location: str = Field(description=\"Summarize the location of the job position\")\n",
    "\n",
    "    job_responsibilities: list[str] = Field(\n",
    "        description=\"The job responsibilities associated with the position\"\n",
    "    )\n",
    "\n",
    "    hards_skills: list[str] = Field(\n",
    "        description=\"The hard skills required for the job position\"\n",
    "    )\n",
    "    soft_skills: list[str] = Field(\n",
    "        description=\"The soft skills required for the job position\"\n",
    "    )\n",
    "\n",
    "    def config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "524a7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_summarize = llm.with_structured_output(SummarizeDescription, include_raw=True)\n",
    "prompt_linkedin = \"\"\"\n",
    "    You are a job description summarizer. \n",
    "    Your task is to summarize the relevant information contained in the job description.\n",
    "    The output should be a JSON object with the following fields:\n",
    "    - resume: A summary of the relevant information contained in the job description.\n",
    "    - smart_working: A boolean flag indicating whether the job is remote or not.\n",
    "    - required: The required skills and qualifications for the job position.\n",
    "    - nice_to_have: The nice-to-have skills and qualifications for the job position.\n",
    "    - company: A summary of the company name and its mission.\n",
    "    - location: A summary of the location of the job position.\n",
    "    - job_responsibilities: The job responsibilities associated with the position.\n",
    "    - hards_skills: The hard skills required for the job position.\n",
    "    - soft_skills: The soft skills required for the job position.\n",
    "\n",
    "    Here is a sample JSON object:\n",
    "    {{\"resume\": \"A software engineer with experience in Python and JavaScript.\",\n",
    "      \"smart_working\": true,\n",
    "      \"required\": \"Experience with Python, JavaScript, and SQL.\",\n",
    "      \"nice_to_have\": \"Experience with React and Docker.\",\n",
    "      \"company\": \"Tech Corp, a leading technology company.\",\n",
    "      \"location\": \"Remote\",\n",
    "      \"job_responsibilities\": [\"Develop software applications\", \"Collaborate with cross-functional teams\"],\n",
    "      \"hards_skills\": [\"Python\", \"JavaScript\", \"SQL\"],\n",
    "      \"soft_skills\": [\"Communication\", \"Teamwork\"]}}\n",
    "\n",
    "    Here is the job description:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9cd0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = prompt_linkedin.format(description=df_jobs.loc[0, \"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eecae7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysts = llm_summarize.invoke([SystemMessage(content=prompt_linkedin)]+[HumanMessage(content=df_jobs.loc[0, \"description\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "167304c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1558"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysts[\"raw\"].usage_metadata[\"total_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e220791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SummarizeDescription(resume='A JavaScript/React developer with 3+ years of experience to work on training data for AI models.', smart_working=True, required='3+ years of experience in software engineering, strong proficiency with JavaScript/React, fluency in English, attention to detail, and ability to articulate complex technical concepts.', nice_to_have=\"Bachelor's or Master's degree in Computer Science, experience with modern JavaScript frameworks, familiarity with frontend testing frameworks, knowledge of state management solutions, and experience with TypeScript.\", company='A prominent player in the AI/LLM space, with a mission to create training data for advanced AI models.', location='Remote, with accepted locations in the US, Canada, LATAM, Europe, Africa, and Asia.', job_responsibilities=['Evaluating AI-generated code', 'Building and evaluating React components', 'Solving coding problems', 'Writing test cases', 'Creating instructions for others'], hards_skills=['JavaScript', 'React', 'Modern web development frameworks and libraries'], soft_skills=['Communication', 'Attention to detail', 'Analytical skills', 'Creativity', 'Continuous learning'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysts[\"parsed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dccd3553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resume': 'A JavaScript/React developer with 3+ years of experience to train large AI language models and create training data for advanced AI models.',\n",
       " 'smart_working': True,\n",
       " 'required': '3+ years of experience in software engineering, strong proficiency with JavaScript/React, fluency in English, attention to detail, and ability to articulate complex technical concepts.',\n",
       " 'nice_to_have': \"Bachelor's or Master's degree in Computer Science, experience with modern JavaScript frameworks, familiarity with frontend testing frameworks, knowledge of state management solutions, and experience with TypeScript.\",\n",
       " 'company': 'A prominent player in the AI/LLM space, with a mission to create training data for advanced AI models.',\n",
       " 'location': '100% remote, with accepted locations in the US, Canada, LATAM, Europe, Africa, and Asia.',\n",
       " 'job_responsibilities': ['Evaluating AI-generated code',\n",
       "  'Building and evaluating React components',\n",
       "  'Solving coding problems',\n",
       "  'Writing test cases',\n",
       "  'Creating instructions for others',\n",
       "  'Engaging in various projects'],\n",
       " 'hards_skills': ['JavaScript',\n",
       "  'React',\n",
       "  'Modern web development frameworks',\n",
       "  'Frontend development'],\n",
       " 'soft_skills': ['Communication',\n",
       "  'Attention to detail',\n",
       "  'Analytical skills',\n",
       "  'Creativity',\n",
       "  'Continuous learning',\n",
       "  'Technical writing']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysts.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d8f07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### **Accepted Locations**\\n\\n\\nWe accept applicants from the US, Canada, and most countries in LATAM and Europe. We are also accepting candidates from some countries in Africa and Asia. For the complete list of accepted locations, click here. This work is 100% remote.\\n\\n**Loom Video**\\n\\n\\nOur Founder/CEO, Gabe Greenberg, created an in\\\\-depth Loom video that we highly recommend you watch! Check it out here: Loom Video\\n\\n**Overview**\\n\\n\\nJoin our expert annotation team to create training data for the world's most advanced AI models. No previous AI experience is necessary. You'll get your foot in the door with one of the most prominent players in the AI/LLM space today. We're primarily seeking JavaScript/React developers with 3\\\\+ years of experience to train large AI language models, helping cutting\\\\-edge generative AI models write better frontend code. Projects typically include discrete, highly variable problems that involve engaging with these models as they learn to code. We currently have 200\\\\+ roles open!\\n\\n**What Will I Be Doing?**\\n\\n* Evaluating the quality of AI\\\\-generated code, including human\\\\-readable summaries of your rationale.\\n* Building and evaluating React components, hooks, and modern JavaScript solutions.\\n* Solving coding problems and writing functional and efficient JavaScript/React code.\\n* Writing robust test cases to confirm code works efficiently and effectively.\\n* Creating instructions to help others and reviewing code before it goes into the model.\\n* Engaging in a variety of projects, from evaluating code snippets to developing full mobile applications using chatbots.\\n\\n**Pay Rates**\\n\\n\\nCompensation rates vary based on location and experience and you can find them in this document. The following rates are starting points and may be subject to change. Expectations are 15\\\\+ hours per week; however, there is no upper limit. You can work as much as you want and will be paid weekly per hour of work done on the platform.\\n\\n**Contract Length**\\n\\n\\nThis is a long\\\\-term contract with no end date. We expect to have work for the next 2 years. You can end the contract at any time, but we hope you will commit to 12 months of work.\\n\\n**Flexible Schedules**\\n\\n\\nDevelopers can set their own hours—ideal candidates will be interested in spending 40 hours a week. You will be with teams, so strong performers will adapt to the urgency of projects and stay engaged, but we are incredibly flexible on working hours. You can take a 3\\\\-hour lunch with no problem. Instead of tracking your hours, you are paid according to time spent on the platform, calculated in the coding exercises.\\n\\n**Interview Process**\\n\\n* Apply using this Ashby form.\\n* If you seem like a good fit, we'll send an async RLHF code review that will take 35 minutes and must be finished within 72 hours of us sending it.\\n* You'll receive credentials to the RLHF platform. We'll then set up a group call to answer any further questions about onboarding with the company.\\n* You'll perform a simulated production\\\\-level task (RLHF task) on the platform. This will be your final interview, which will ultimately determine your employment and leveling. Successful completion of this process provides you with an opportunity to work on projects as they become available.\\n\\n**Tech Stack Priorities**\\n\\n\\nThe current priority for this team is frontend engineers who are well versed in JavaScript, React, and modern web development frameworks and libraries.\\n\\n**Required Qualifications**\\n\\n* 3\\\\+ years of experience in a software engineering/software development role.\\n* Strong proficiency with JavaScript/React and frontend development.\\n* Complete fluency in the English language.\\n* Ability to articulate complex technical concepts clearly and engagingly.\\n* Excellent attention to detail and ability to maintain consistency in writing. Solid understanding of grammar, punctuation, and style guidelines.\\n\\n**Nice To Haves:**\\n\\n* Bachelor's or Master's degree in Computer Science.\\n* Experience with modern JavaScript frameworks and libraries (Next.js, Vue, Angular).\\n* Familiarity with frontend testing frameworks (Jest, React Testing Library, Cypress).\\n* Knowledge of state management solutions (Redux, Context API, MobX).\\n* Experience with TypeScript and modern frontend tooling.\\n* Recognized accomplishments or contributions to the coding community or in projects.\\n* Proven analytical skills with an ability to approach problems creatively.\\n* Adept communication skills, especially when understanding and discussing project requirements.\\n* A commitment to continuous learning and staying updated with the latest coding advancements and best practices.\\n* Enthusiasm for teaching AI models and experience with technical writing!\\n\\n\\nIf you're passionate about JavaScript, React, and the future of frontend development, this is an excellent opportunity to contribute to cutting\\\\-edge AI technology while leveraging your expertise!\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs.loc[0, \"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "939ab596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33e52a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33f1ad78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### **Accepted Locations**\\n\\n\\nWe accept applicants from the US, Canada, and most countries in LATAM and Europe. We are also accepting candidates from some countries in Africa and Asia. For the complete list of accepted locations, click here. This work is 100% remote.\\n\\n**Loom Video**\\n\\n\\nOur Founder/CEO, Gabe Greenberg, created an in\\\\-depth Loom video that we highly recommend you watch! Check it out here: Loom Video\\n\\n**Overview**\\n\\n\\nJoin our expert annotation team to create training data for the world's most advanced AI models. No previous AI experience is necessary. You'll get your foot in the door with one of the most prominent players in the AI/LLM space today. We're primarily seeking JavaScript/React developers with 3\\\\+ years of experience to train large AI language models, helping cutting\\\\-edge generative AI models write better frontend code. Projects typically include discrete, highly variable problems that involve engaging with these models as they learn to code. We currently have 200\\\\+ roles open!\\n\\n**What Will I Be Doing?**\\n\\n* Evaluating the quality of AI\\\\-generated code, including human\\\\-readable summaries of your rationale.\\n* Building and evaluating React components, hooks, and modern JavaScript solutions.\\n* Solving coding problems and writing functional and efficient JavaScript/React code.\\n* Writing robust test cases to confirm code works efficiently and effectively.\\n* Creating instructions to help others and reviewing code before it goes into the model.\\n* Engaging in a variety of projects, from evaluating code snippets to developing full mobile applications using chatbots.\\n\\n**Pay Rates**\\n\\n\\nCompensation rates vary based on location and experience and you can find them in this document. The following rates are starting points and may be subject to change. Expectations are 15\\\\+ hours per week; however, there is no upper limit. You can work as much as you want and will be paid weekly per hour of work done on the platform.\\n\\n**Contract Length**\\n\\n\\nThis is a long\\\\-term contract with no end date. We expect to have work for the next 2 years. You can end the contract at any time, but we hope you will commit to 12 months of work.\\n\\n**Flexible Schedules**\\n\\n\\nDevelopers can set their own hours—ideal candidates will be interested in spending 40 hours a week. You will be with teams, so strong performers will adapt to the urgency of projects and stay engaged, but we are incredibly flexible on working hours. You can take a 3\\\\-hour lunch with no problem. Instead of tracking your hours, you are paid according to time spent on the platform, calculated in the coding exercises.\\n\\n**Interview Process**\\n\\n* Apply using this Ashby form.\\n* If you seem like a good fit, we'll send an async RLHF code review that will take 35 minutes and must be finished within 72 hours of us sending it.\\n* You'll receive credentials to the RLHF platform. We'll then set up a group call to answer any further questions about onboarding with the company.\\n* You'll perform a simulated production\\\\-level task (RLHF task) on the platform. This will be your final interview, which will ultimately determine your employment and leveling. Successful completion of this process provides you with an opportunity to work on projects as they become available.\\n\\n**Tech Stack Priorities**\\n\\n\\nThe current priority for this team is frontend engineers who are well versed in JavaScript, React, and modern web development frameworks and libraries.\\n\\n**Required Qualifications**\\n\\n* 3\\\\+ years of experience in a software engineering/software development role.\\n* Strong proficiency with JavaScript/React and frontend development.\\n* Complete fluency in the English language.\\n* Ability to articulate complex technical concepts clearly and engagingly.\\n* Excellent attention to detail and ability to maintain consistency in writing. Solid understanding of grammar, punctuation, and style guidelines.\\n\\n**Nice To Haves:**\\n\\n* Bachelor's or Master's degree in Computer Science.\\n* Experience with modern JavaScript frameworks and libraries (Next.js, Vue, Angular).\\n* Familiarity with frontend testing frameworks (Jest, React Testing Library, Cypress).\\n* Knowledge of state management solutions (Redux, Context API, MobX).\\n* Experience with TypeScript and modern frontend tooling.\\n* Recognized accomplishments or contributions to the coding community or in projects.\\n* Proven analytical skills with an ability to approach problems creatively.\\n* Adept communication skills, especially when understanding and discussing project requirements.\\n* A commitment to continuous learning and staying updated with the latest coding advancements and best practices.\\n* Enthusiasm for teaching AI models and experience with technical writing!\\n\\n\\nIf you're passionate about JavaScript, React, and the future of frontend development, this is an excellent opportunity to contribute to cutting\\\\-edge AI technology while leveraging your expertise!\\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs.loc[0, \"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc57d28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giuseppe/projetos-pessoais/linkedin-bot/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: what is snowflake?\n",
      "tensor(0.2666) The Data Cloud!\n",
      "tensor(0.0663) Mexico City of Course!\n",
      "Query: Where can I get the best tacos?\n",
      "tensor(0.2716) Mexico City of Course!\n",
      "tensor(0.1085) The Data Cloud!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model_name = 'Snowflake/snowflake-arctic-embed-l-v2.0'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Define the queries and documents\n",
    "queries = ['what is snowflake?', 'Where can I get the best tacos?']\n",
    "documents = ['The Data Cloud!', 'Mexico City of Course!']\n",
    "\n",
    "# Compute embeddings: use `prompt_name=\"query\"` to encode queries!\n",
    "query_embeddings = model.encode(queries, prompt_name=\"query\") \n",
    "document_embeddings = model.encode(documents)\n",
    "\n",
    "# Compute cosine similarity scores\n",
    "scores = model.similarity(query_embeddings, document_embeddings)\n",
    "\n",
    "# Output the results\n",
    "for query, query_scores in zip(queries, scores):\n",
    "    doc_score_pairs = list(zip(documents, query_scores))\n",
    "    doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "    print(\"Query:\", query)\n",
    "    for document, score in doc_score_pairs:\n",
    "        print(score, document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6979e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"/home/giuseppe/Downloads/giuseppe_tinti.pdf\")\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "edb1858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with RenderCV', 'creationdate': '2025-02-06T18:58:47+00:00', 'author': 'Giuseppe Tinti', 'keywords': '', 'moddate': '2025-02-06T18:58:47+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': 'Giuseppe Tinti CV', 'trapped': '/False', 'source': '/home/giuseppe/Downloads/giuseppe_tinti.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Giuseppe Tinti\n",
      "♂¶ap-¶arker-altSestu/CA /envel⌢pegiuseppe31tinti@gmail.com ♂phone-alt39 3513244561 /githubGiuseppe31-s /linkedin-inGiuseppe Tinti\n",
      "Chi Sono\n",
      "Data Scientist con oltre 2 anni di esperienza , specializzato nell’analisi dei dati e nella costruzione di\n",
      "modelli predittivi. Competente in Python, SQL e tecniche statistiche, con conoscenze in ambito Cloud\n",
      "(AWS) e nel deployment di modelli in produzione. Particolarmente interessato ai paradigmi di previsione e\n",
      "regressione, con l’obiettivo di continuare a sviluppare e applicare soluzioni data-driven per supportare le decisioni\n",
      "strategiche.\n",
      "Esperienza Professionale\n",
      "Data Scientist Junior\n",
      "Athlos S.R.L\n",
      "Cagliari, ITA\n",
      "Mar 2024 – Presente\n",
      "◦ Ottimizzazione della velocit `a del 30% e della qualit` a delle risposte in un modello RAG (Retriever\n",
      "Augmented Generation), utilizzando tecniche avanzate come fine-tuning di Transformers.\n",
      "◦ Sviluppo di modelli di programmazione lineare per l’ottimizzazione dei percorsi veicolari, utilizzando\n",
      "librerie come Pulp e Pyomo, su grafi per calcolare i percorsi ottimali.\n",
      "◦ Costruzione di pipeline ELT (Extract, Load, Transform) da fonti multiple, con inserimento dei dati in\n",
      "un database (Postgres), ottimizzando l’automazione tramite Docker, scheduling e DBT-core.\n",
      "◦ Sviluppo di modelli di previsione per il turismo e interpretazione dei risultati per ottimizzare le strategie\n",
      "decisionali. Utilizzo di tecniche di hierarchical forecast per migliorare la previsione.\n",
      "Stage Data Scientist\n",
      "Oncase\n",
      "Recife, BRA\n",
      "Mar 2023 – Dic 2023\n",
      "◦ Esperienza con i Metodi Agili ( Jira, Confluence).\n",
      "◦ Sviluppo di un sistema di raccomandazione (BestNextOffer) per e-commerce, incremento del 120%\n",
      "del tasso di conversione degli utenti (acquisto del prodotto per campagna).\n",
      "◦ Clustering degli utenti per segmentazione e metriche pi` u personalizzate.\n",
      "◦ Riduzione della dimensionalit` a medianteAutoencoder e UMAP.\n",
      "◦ Ingegneria di prompt personalizzati per task specifiche utilizzando l’API di OpenAI.\n",
      "Assistente di Riassicurazione\n",
      "Excelsior Seguros\n",
      "Recife, BRA\n",
      "Mag 2021 – Dic 2022\n",
      "◦ Automazione delle attivit` a conPython.\n",
      "◦ Interrogazioni database (Microsoft SQL Server).\n",
      "◦ Monitoraggio della distribuzione dei sinistri, delle tasse e dei premi tra vari riassicuratori.\n",
      "Formazione\n",
      "Universit`a Cattolica di Pernambuco\n",
      "Laurea in Economia\n",
      "Ago 2019 – Dic 2023\n",
      "Competenze Tecniche\n",
      "Python, SQL, Linux, Github, Docker, DBT-Core, AWS (S3, Athena, SageMaker), Scikit-learn, Tensorflow,\n",
      "Pandas, Numpy, Pyomo, Pulp, Flask, Matplotlib, Langchain, Xgboost, Scipy, Statsmodels, Hugging Face, Excel.\n",
      "Lingue\n",
      "Italiano: Fluente\n",
      "Portoghese: Fluente\n",
      "Inglese: B2\n",
      "Autorizzo il trattamento dei dati personali nel CV secondo D. Lgs. 196/2003 e Regolamento UE 2016/679\n",
      "Giuseppe Tinti - Page 1 of 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"{pages[0].metadata}\\n\")\n",
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e24a2786",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = model.encode(pages[0].page_content, prompt_name=\"query\") \n",
    "document_embeddings = model.encode([df_jobs.loc[i, \"description\"] for i in range(len(df_jobs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c040afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.similarity(query_embeddings, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cabb99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3311, 0.3311, 0.3311, 0.3311, 0.5028, 0.3421, 0.4652, 0.3487, 0.4018,\n",
      "         0.4394]])\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bfb6b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c67ca343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62352/1549207232.py:1: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  np.array(np.argsort(score)[0])[::-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 6, 9, 8, 7, 5, 3, 2, 1, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.argsort(score)[0])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee077c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mavriq, parte di Moltiply Group, è la tech company a cui appartengono alcuni tra i più importanti brand di comparazione ed intermediazione online in Italia (MutuiOnline.it, Segugio.it, SOStariffe.it, Trovaprezzi.it, Switcho e molti altri) e all’estero (LeLynx.fr, Rastreator, Pricewise, Verivox). I servizi offerti dai brand di Mavriq aiutano con trasparenza i consumatori a trovare ciò di cui hanno bisogno, al miglior prezzo. Siamo un team di circa 1\\.000 “smart disruptors” distribuiti in Europa, America Latina ed Asia.\n",
      "\n",
      "  \n",
      "\n",
      "Il successo di Mavriq è legato al successo dei nostri team. Per questo, siamo oggi alla ricerca di un nuovo o una nuova team member con cui continuare a scrivere la nostra storia nel mondo della comparazione ed intermediazione internazionale.\n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "**Posizione:**\n",
      "--------------\n",
      "\n",
      "**Il ruolo**\n",
      "\n",
      "\n",
      "Per supportare la crescita dei progetti di Machine Learning in Mavriq per i brand Segugio.it, PrestitiOnline e altri, siamo alla ricerca di un\\-a Junior Data Scientist che, riportando alla risorsa Senior del team, supporterà lo sviluppo di algoritmi avanzati per l’ottimizzazione dei nostri processi di acquisizione e di gestione dei clienti.\n",
      "\n",
      " **Location**\n",
      "\n",
      "\n",
      "La tua sede di lavoro sarà in Via Desenzano 2 a Milano (MM1 Gambara). Lavoriamo in modalità **ibrida**: 2 giorni in ufficio e 3 giorni in smart working, con flessibilità in ingresso e in uscita. I due giorni in ufficio sono un momento per i nostri team di aggregazione e scambio, e ci permettono di continuare ad alimentare la nostra Cultura Mavriq.\n",
      "\n",
      " **Come lavoriamo e cosa farai**\n",
      "\n",
      "\n",
      "Il team di Data Scientist, inserito all'interno della Funzione Marketing, si occupa di ideare, implementare e mantenere diversi modelli machine learning a supporto del business.\n",
      "\n",
      "  \n",
      "\n",
      "Nello specifico, ti occuperai di:\n",
      "\n",
      "* Realizzare progetti complessi di data analisi, con la responsabilità sull’intero ciclo di vita di un “data product”, dall’estrazione e trasformazione del dato fino alla realizzazione e alla messa in produzione dei modelli di machine learning.\n",
      "* Comunicare intuizioni e risultati ricavati dai dati in modo efficace e facilitandone la comprensione ai non addetti ai lavori.\n",
      "* Interagire con analisti ed esperti di business per identificare opportunità innovative.\n",
      "* Collaborare nella creazione di processi data\\-driven, definendo best\\-practice per la raccolta e l’uso dei dati.\n",
      "\n",
      "**Requisiti:**\n",
      "--------------\n",
      "\n",
      "**Di cosa avrai bisogno per il ruolo**\n",
      "\n",
      "* Breve esperienza pregressa in ambito Data Science, specialmente in Machine Learning. Oppure una forte motivazione a costruire il tuo percorso in Data Science.\n",
      "* Buona conoscenza pratica di statistica e machine learning,\n",
      "* Competenza e abilità nell’uso Python e delle sue librerie per Data Science e Machine Learning (Numpy, Pandas, Scikit\\-learn, ...)\n",
      "* Competenza nell’uso di database relazionali (MySQL, SqlServer, ...),\n",
      "* Familiarità con l’ambiente Linux,\n",
      "* Approccio data\\-driven alla risoluzione dei problemi,\n",
      "* Capacità di lavorare autonomamente e per obiettivi, bilanciando in maniera efficiente richieste e scadenze,\n",
      "* Capacità di interagire e comunicare efficacemente con interlocutori con profili diversi (manager, business analyst, sviluppatori, ...),\n",
      "* Comprensione dei principali concetti MLOps come deployment e monitoraggio dei modelli,\n",
      "* Buona padronanza della lingua inglese (B2\\-C1\\) e italiana (C1\\).\n",
      "\n",
      " **Cosa troverai da noi**\n",
      "\n",
      "* Ambiente di lavoro giovane, dinamico e informale, flessibilità di orario, smartworking, formazione continua e partecipazione a eventi e conferenze.\n",
      "* Sede spaziosa, open space, con diverse sale break e dotata di ciò di cui avrai bisogno per lavorare.\n",
      "* Pacchetto di benefit, come assicurazione sanitaria, buoni pasto e welfare.\n",
      "\n",
      "  \n",
      "\n",
      "Non vediamo l’ora di conoscerti!\n",
      "\n",
      "**Altre informazioni:**\n",
      "-----------------------\n",
      "\n",
      "Puoi scoprire di più su di noi a questo video. Leggere le nostre Recensioni su Indeed o Glassdoor. Familiarizzare con i nostri principi guida qui.\n",
      "\n",
      " *La ricerca è rivolta ad ambo i sessi (ai sensi delle Leggi n. 903/77 e n. 125/91\\).*\n",
      "\n",
      "*Si richiede esplicito consenso al trattamento dei dati personali (ex D.Lgs. 196/03 e GDPR \\- Reg.UE. 2016/679\\).*\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_jobs.loc[6, \"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb368a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
